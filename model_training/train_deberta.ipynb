{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install seqeval evaluate -q\n",
    "!pip install transformers[torch]\n",
    "!pip install accelerate -U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import argparse\n",
    "from itertools import chain\n",
    "from functools import partial\n",
    "\n",
    "import torch\n",
    "from transformers import AutoTokenizer, Trainer, TrainingArguments\n",
    "from transformers import AutoModelForTokenClassification, DataCollatorForTokenClassification\n",
    "import evaluate\n",
    "from datasets import Dataset, features\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAINING_MODEL_PATH = \"microsoft/deberta-v3-base\"\n",
    "TRAINING_MAX_LENGTH = 1024\n",
    "OUTPUT_DIR = \"output\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = json.load(open(\"/content/drive/MyDrive/pii_detector_training_spacy/train.json\"))\n",
    "\n",
    "# downsampling of negative examples\n",
    "p=[] # positive samples (contain relevant labels)\n",
    "n=[] # negative samples (presumably contain entities that are possibly wrongly classified as entity)\n",
    "for d in data:\n",
    "    if any(np.array(d[\"labels\"]) != \"O\"): p.append(d)\n",
    "    else: n.append(d)\n",
    "print(\"original datapoints: \", len(data))\n",
    "\n",
    "external = json.load(open(\"/content/drive/MyDrive/pii_detector_training_spacy/pii_dataset_fixed.json\"))\n",
    "print(\"external datapoints: \", len(external))\n",
    "\n",
    "moredata = json.load(open(\"/content/drive/MyDrive/pii_detector_training_spacy/moredata_dataset_fixed.json\"))\n",
    "print(\"moredata datapoints: \", len(moredata))\n",
    "\n",
    "data = moredata+external+p+n[:len(n)//3]\n",
    "print(\"combined: \", len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_labels = sorted(list(set(chain(*[x[\"labels\"] for x in data]))))\n",
    "label2id = {l: i for i,l in enumerate(all_labels)}\n",
    "id2label = {v:k for k,v in label2id.items()}\n",
    "\n",
    "target = [\n",
    "    'B-EMAIL', 'B-ID_NUM', 'B-NAME_STUDENT', 'B-PHONE_NUM',\n",
    "    'B-STREET_ADDRESS', 'B-URL_PERSONAL', 'B-USERNAME', 'I-ID_NUM',\n",
    "    'I-NAME_STUDENT', 'I-PHONE_NUM', 'I-STREET_ADDRESS', 'I-URL_PERSONAL'\n",
    "]\n",
    "\n",
    "print(id2label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(example, tokenizer, label2id, max_length):\n",
    "\n",
    "    # rebuild text from tokens\n",
    "    text = []\n",
    "    labels = []\n",
    "\n",
    "    for t, l, ws in zip(\n",
    "        example[\"tokens\"], example[\"provided_labels\"], example[\"trailing_whitespace\"]\n",
    "    ):\n",
    "        text.append(t)\n",
    "        labels.extend([l] * len(t))\n",
    "\n",
    "        if ws:\n",
    "            text.append(\" \")\n",
    "            labels.append(\"O\")\n",
    "\n",
    "    # actual tokenization\n",
    "    tokenized = tokenizer(\"\".join(text), return_offsets_mapping=True, max_length=max_length)\n",
    "\n",
    "    labels = np.array(labels)\n",
    "\n",
    "    text = \"\".join(text)\n",
    "    token_labels = []\n",
    "\n",
    "    for start_idx, end_idx in tokenized.offset_mapping:\n",
    "        # CLS token\n",
    "        if start_idx == 0 and end_idx == 0:\n",
    "            token_labels.append(label2id[\"O\"])\n",
    "            continue\n",
    "\n",
    "        # case when token starts with whitespace\n",
    "        if text[start_idx].isspace():\n",
    "            start_idx += 1\n",
    "\n",
    "        token_labels.append(label2id[labels[start_idx]])\n",
    "\n",
    "    length = len(tokenized.input_ids)\n",
    "\n",
    "    return {**tokenized, \"labels\": token_labels, \"length\": length}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(TRAINING_MODEL_PATH)\n",
    "\n",
    "ds = Dataset.from_dict({\n",
    "    \"full_text\": [x[\"full_text\"] for x in data],\n",
    "    \"document\": [str(x[\"document\"]) for x in data],\n",
    "    \"tokens\": [x[\"tokens\"] for x in data],\n",
    "    \"trailing_whitespace\": [x[\"trailing_whitespace\"] for x in data],\n",
    "    \"provided_labels\": [x[\"labels\"] for x in data],\n",
    "})\n",
    "ds = ds.map(tokenize, fn_kwargs={\"tokenizer\": tokenizer, \"label2id\": label2id, \"max_length\": TRAINING_MAX_LENGTH}, num_proc=3)\n",
    "# ds = ds.class_encode_column(\"group\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = ds[0]\n",
    "\n",
    "for t,l in zip(x[\"tokens\"], x[\"provided_labels\"]):\n",
    "    if l != \"O\":\n",
    "        print((t,l))\n",
    "\n",
    "print(\"*\"*100)\n",
    "\n",
    "for t, l in zip(tokenizer.convert_ids_to_tokens(x[\"input_ids\"]), x[\"labels\"]):\n",
    "    if id2label[l] != \"O\":\n",
    "        print((t,id2label[l]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from seqeval.metrics import recall_score, precision_score\n",
    "from seqeval.metrics import classification_report\n",
    "from seqeval.metrics import f1_score\n",
    "\n",
    "def compute_metrics(p, all_labels):\n",
    "    predictions, labels = p\n",
    "    predictions = np.argmax(predictions, axis=2)\n",
    "\n",
    "    # Remove ignored index (special tokens)\n",
    "    true_predictions = [\n",
    "        [all_labels[p] for (p, l) in zip(prediction, label) if l != -100]\n",
    "        for prediction, label in zip(predictions, labels)\n",
    "    ]\n",
    "    true_labels = [\n",
    "        [all_labels[l] for (p, l) in zip(prediction, label) if l != -100]\n",
    "        for prediction, label in zip(predictions, labels)\n",
    "    ]\n",
    "\n",
    "    recall = recall_score(true_labels, true_predictions)\n",
    "    precision = precision_score(true_labels, true_predictions)\n",
    "    f5_score = (1 + 5*5) * recall * precision / (5*5*precision + recall)\n",
    "\n",
    "    results = {\n",
    "        'recall': recall,\n",
    "        'precision': precision,\n",
    "        'f5': f5_score\n",
    "    }\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForTokenClassification.from_pretrained(\n",
    "    TRAINING_MODEL_PATH,\n",
    "    num_labels=len(all_labels),\n",
    "    id2label=id2label,\n",
    "    label2id=label2id,\n",
    "    ignore_mismatched_sizes=True\n",
    ")\n",
    "collator = DataCollatorForTokenClassification(tokenizer, pad_to_multiple_of=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = TrainingArguments(\n",
    "    output_dir=OUTPUT_DIR,\n",
    "    fp16=True,\n",
    "    learning_rate=2e-5,\n",
    "    num_train_epochs=3,\n",
    "    per_device_train_batch_size=4,\n",
    "    gradient_accumulation_steps=2,\n",
    "    report_to=\"none\",\n",
    "    evaluation_strategy=\"no\",\n",
    "    do_eval=False,\n",
    "    save_total_limit=1,\n",
    "    logging_steps=20,\n",
    "    lr_scheduler_type='cosine',\n",
    "    metric_for_best_model=\"f5\",\n",
    "    greater_is_better=True,\n",
    "    warmup_ratio=0.1,\n",
    "    weight_decay=0.01\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=args,\n",
    "    train_dataset=ds,\n",
    "    data_collator=collator,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=partial(compute_metrics, all_labels=all_labels),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_model(\"deberta3base_1024\")\n",
    "tokenizer.save_pretrained(\"deberta3base_1024\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!zip -r deberta3base_1024.zip /content/deberta3base_1024"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
